{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-22T13:41:00.909290Z","iopub.execute_input":"2022-04-22T13:41:00.910094Z","iopub.status.idle":"2022-04-22T13:41:00.921946Z","shell.execute_reply.started":"2022-04-22T13:41:00.909987Z","shell.execute_reply":"2022-04-22T13:41:00.921173Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Some check about libraries","metadata":{}},{"cell_type":"code","source":"pip install keras","metadata":{"execution":{"iopub.status.busy":"2022-04-22T13:41:00.923230Z","iopub.execute_input":"2022-04-22T13:41:00.924082Z","iopub.status.idle":"2022-04-22T13:41:09.204178Z","shell.execute_reply.started":"2022-04-22T13:41:00.924045Z","shell.execute_reply":"2022-04-22T13:41:09.203102Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"pip install --upgrade tensorflow","metadata":{"execution":{"iopub.status.busy":"2022-04-22T13:41:09.206521Z","iopub.execute_input":"2022-04-22T13:41:09.206892Z","iopub.status.idle":"2022-04-22T13:41:17.889251Z","shell.execute_reply.started":"2022-04-22T13:41:09.206842Z","shell.execute_reply":"2022-04-22T13:41:17.888242Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"pip install --upgrade tensorflow-gpu","metadata":{"execution":{"iopub.status.busy":"2022-04-22T13:41:17.890874Z","iopub.execute_input":"2022-04-22T13:41:17.891121Z","iopub.status.idle":"2022-04-22T13:41:26.690091Z","shell.execute_reply.started":"2022-04-22T13:41:17.891090Z","shell.execute_reply":"2022-04-22T13:41:26.689004Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import os\nfrom glob import glob\nimport random\nimport time\nimport tensorflow\nimport datetime\nos.environ['KERAS_BACKEND'] = 'tensorflow'\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # 3 = INFO, WARNING, and ERROR\nfrom tqdm import tqdm\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import FileLink\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nimport seaborn as sns \n%matplotlib inline\nfrom IPython.display import display, Image\nimport matplotlib.image as mpimg\nimport cv2\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_files       \nfrom keras.utils import np_utils\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import log_loss\n\nfrom tensorflow import keras \n\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.applications.vgg16 import VGG16\n\n\ndataset = pd.read_csv('../input/state-farm-distracted-driver-detection/driver_imgs_list.csv')\ndataset.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T13:41:26.692149Z","iopub.execute_input":"2022-04-22T13:41:26.692426Z","iopub.status.idle":"2022-04-22T13:41:31.955775Z","shell.execute_reply.started":"2022-04-22T13:41:26.692378Z","shell.execute_reply":"2022-04-22T13:41:31.954846Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Groupby subjects\nby_drivers = dataset.groupby('subject') \n# Groupby unique drivers\nunique_drivers = by_drivers.groups.keys() # drivers id\nprint('There are : ',len(unique_drivers), ' unique drivers')\nprint('There is a mean of ',round(dataset.groupby('subject').count()['classname'].mean()), ' images by driver.')","metadata":{"execution":{"iopub.status.busy":"2022-04-22T13:41:31.957437Z","iopub.execute_input":"2022-04-22T13:41:31.957733Z","iopub.status.idle":"2022-04-22T13:41:31.991064Z","shell.execute_reply.started":"2022-04-22T13:41:31.957700Z","shell.execute_reply":"2022-04-22T13:41:31.990097Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"The 10 classes to classify are :\n- c0: safe driving\n- c1: texting - right\n- c2: talking on the phone - right\n- c3: texting - left\n- c4: talking on the phone - left\n- c5: operating the radio\n- c6: drinking\n- c7: reaching behind\n- c8: hair and makeup\n- c9: talking to passenger","metadata":{}},{"cell_type":"code","source":"NUMBER_CLASSES = 10 ","metadata":{"execution":{"iopub.status.busy":"2022-04-22T13:41:31.992256Z","iopub.execute_input":"2022-04-22T13:41:31.992545Z","iopub.status.idle":"2022-04-22T13:41:31.997394Z","shell.execute_reply.started":"2022-04-22T13:41:31.992514Z","shell.execute_reply":"2022-04-22T13:41:31.996471Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Read with opencv\ndef get_cv2_image(path, img_rows, img_cols, color_type=3):\n    \"\"\"\n    Function that return an opencv image from the path and the right number of dimension\n    \"\"\"\n    if color_type == 1: # Loading as Grayscale image\n        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    elif color_type == 3: # Loading as color image\n        img = cv2.imread(path, cv2.IMREAD_COLOR)\n    img = cv2.resize(img, (img_rows, img_cols)) # Reduce size\n    return img\n\n# Loading Training dataset\ndef load_train(img_rows, img_cols, color_type=3):\n    \"\"\"\n    Return train images and train labels from the original path\n    \"\"\"\n    train_images = [] \n    train_labels = []\n    # Loop over the training folder \n    for classed in tqdm(range(NUMBER_CLASSES)):\n        print('Loading directory c{}'.format(classed))\n        files = glob(os.path.join('../input/state-farm-distracted-driver-detection/imgs/train/c' + str(classed), '*.jpg'))\n        for file in files:\n            img = get_cv2_image(file, img_rows, img_cols, color_type)\n            train_images.append(img)\n            train_labels.append(classed)\n    return train_images, train_labels \n\ndef read_and_normalize_train_data(img_rows, img_cols, color_type):\n    \"\"\"\n    Load + categorical + split\n    \"\"\"\n    X, labels = load_train(img_rows, img_cols, color_type)\n    y = np_utils.to_categorical(labels, 10) #categorical train label\n    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # split into train and test\n    x_train = np.array(x_train, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)\n    x_test = np.array(x_test, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)\n    \n    return x_train, x_test, y_train, y_test\n\n# Loading validation dataset\ndef load_test(size=200000, img_rows=64, img_cols=64, color_type=3):\n    \"\"\"\n    Same as above but for validation dataset\n    \"\"\"\n    path = os.path.join('../input/state-farm-distracted-driver-detection/imgs/test', '*.jpg')\n    files = sorted(glob(path))\n    X_test, X_test_id = [], []\n    total = 0\n    files_size = len(files)\n    for file in tqdm(files):\n        if total >= size or total >= files_size:\n            break\n        file_base = os.path.basename(file)\n        img = get_cv2_image(file, img_rows, img_cols, color_type)\n        X_test.append(img)\n        X_test_id.append(file_base)\n        total += 1\n    return X_test, X_test_id\n\ndef read_and_normalize_sampled_test_data(size, img_rows, img_cols, color_type=3):\n    test_data, test_ids = load_test(size, img_rows, img_cols, color_type)   \n    test_data = np.array(test_data, dtype=np.uint8)\n    test_data = test_data.reshape(-1,img_rows,img_cols,color_type)\n    return test_data, test_ids","metadata":{"execution":{"iopub.status.busy":"2022-04-22T13:41:31.998848Z","iopub.execute_input":"2022-04-22T13:41:31.999628Z","iopub.status.idle":"2022-04-22T13:41:32.020312Z","shell.execute_reply.started":"2022-04-22T13:41:31.999583Z","shell.execute_reply":"2022-04-22T13:41:32.019172Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"img_rows = 64 # dimension of images\nimg_cols = 64\ncolor_type = 1 # grey\nnb_test_samples = 200\n\n# loading train images\nx_train, x_test, y_train, y_test = read_and_normalize_train_data(img_rows, img_cols, color_type)\n\n# loading validation images\ntest_files, test_targets = read_and_normalize_sampled_test_data(nb_test_samples, img_rows, img_cols, color_type)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T13:41:32.021808Z","iopub.execute_input":"2022-04-22T13:41:32.022088Z","iopub.status.idle":"2022-04-22T13:45:12.552349Z","shell.execute_reply.started":"2022-04-22T13:41:32.022048Z","shell.execute_reply":"2022-04-22T13:45:12.550937Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"activity_map = {'c0': 'Safe driving', \n                'c1': 'Texting - right', \n                'c2': 'Talking on the phone - right', \n                'c3': 'Texting - left', \n                'c4': 'Talking on the phone - left', \n                'c5': 'Operating the radio', \n                'c6': 'Drinking', \n                'c7': 'Reaching behind', \n                'c8': 'Hair and makeup', \n                'c9': 'Talking to passenger'}\n\n\nplt.figure(figsize = (12, 20))\nimage_count = 1\nBASE_URL = '../input/state-farm-distracted-driver-detection/imgs/train/'\nfor directory in os.listdir(BASE_URL):\n    if directory[0] != '.':\n        for i, file in enumerate(os.listdir(BASE_URL + directory)):\n            if i == 1:\n                break\n            else:\n                fig = plt.subplot(5, 2, image_count)\n                image_count += 1\n                image = mpimg.imread(BASE_URL + directory + '/' + file)\n                plt.imshow(image)\n                plt.title(activity_map[directory])","metadata":{"execution":{"iopub.status.busy":"2022-04-22T13:45:16.211750Z","iopub.execute_input":"2022-04-22T13:45:16.212010Z","iopub.status.idle":"2022-04-22T13:45:18.604800Z","shell.execute_reply.started":"2022-04-22T13:45:16.211979Z","shell.execute_reply":"2022-04-22T13:45:18.603859Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"batch_size = 40 \nnb_epoch = 6 ","metadata":{"execution":{"iopub.status.busy":"2022-04-22T13:45:18.606044Z","iopub.execute_input":"2022-04-22T13:45:18.606456Z","iopub.status.idle":"2022-04-22T13:45:18.611393Z","shell.execute_reply.started":"2022-04-22T13:45:18.606400Z","shell.execute_reply":"2022-04-22T13:45:18.610401Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"models_dir = \"saved_models\"\nif not os.path.exists(models_dir):\n    os.makedirs(models_dir)\n    \ncheckpointer = ModelCheckpoint(filepath='saved_models/weights_best_vanilla.hdf5', \n                               monitor='val_loss', mode='min',\n                               verbose=1, save_best_only=True)\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n#callbacks = [checkpointer, es]","metadata":{"execution":{"iopub.status.busy":"2022-04-22T13:45:18.613022Z","iopub.execute_input":"2022-04-22T13:45:18.613485Z","iopub.status.idle":"2022-04-22T13:45:18.626593Z","shell.execute_reply.started":"2022-04-22T13:45:18.613445Z","shell.execute_reply":"2022-04-22T13:45:18.625528Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def create_model():\n    model = Sequential()\n\n    ## CNN 1\n    model.add(Conv2D(32,(3,3),activation='relu',input_shape=(img_rows, img_cols, color_type)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization(axis = 3))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    model.add(Dropout(0.3))\n\n    ## CNN 2\n    model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization(axis = 3))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    model.add(Dropout(0.3))\n\n    ## CNN 3\n    model.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization(axis = 3))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    model.add(Dropout(0.5))\n\n    ## Output\n    model.add(Flatten())\n    model.add(Dense(512,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(128,activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(10,activation='softmax'))\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-22T13:45:18.627909Z","iopub.execute_input":"2022-04-22T13:45:18.628646Z","iopub.status.idle":"2022-04-22T13:45:18.643137Z","shell.execute_reply.started":"2022-04-22T13:45:18.628609Z","shell.execute_reply":"2022-04-22T13:45:18.642033Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model = create_model()\n\n# More details about the layers\nmodel.summary()\n\n# Compiling the model\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-04-22T13:45:18.644394Z","iopub.execute_input":"2022-04-22T13:45:18.644799Z","iopub.status.idle":"2022-04-22T13:45:19.052667Z","shell.execute_reply.started":"2022-04-22T13:45:18.644764Z","shell.execute_reply":"2022-04-22T13:45:19.051519Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"#### Training model","metadata":{}},{"cell_type":"code","source":"history = model.fit(x_train, y_train, \n          validation_data=(x_test, y_test),\n          epochs=nb_epoch, batch_size=batch_size, verbose=1)\n\n#model.load_weights('saved_models/weights_best_vanilla.hdf5')\nprint('History of the training',history.history)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T13:45:19.054174Z","iopub.execute_input":"2022-04-22T13:45:19.054723Z","iopub.status.idle":"2022-04-22T14:17:43.497863Z","shell.execute_reply.started":"2022-04-22T13:45:19.054687Z","shell.execute_reply":"2022-04-22T14:17:43.496561Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def plot_train_history(history):\n    \"\"\"\n    Plot the validation accuracy and validation loss over epochs\n    \"\"\"\n    # Summarize history for accuracy\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('Model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n\n    # Summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n    \nplot_train_history(history)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T14:17:43.501490Z","iopub.execute_input":"2022-04-22T14:17:43.501931Z","iopub.status.idle":"2022-04-22T14:17:43.970691Z","shell.execute_reply.started":"2022-04-22T14:17:43.501895Z","shell.execute_reply":"2022-04-22T14:17:43.969886Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"#### Prediction on test set","metadata":{}},{"cell_type":"code","source":"def plot_test_class(model, test_files, image_number, color_type=1):\n    \"\"\"\n    Function that tests or model on test images and show the results\n    \"\"\"\n    img_brute = test_files[image_number]\n    img_brute = cv2.resize(img_brute,(img_rows,img_cols))\n    plt.imshow(img_brute, cmap='gray')\n\n    new_img = img_brute.reshape(-1,img_rows,img_cols,color_type)\n\n    y_prediction = model.predict(new_img, batch_size=batch_size, verbose=1)\n    print('Y prediction: {}'.format(y_prediction))\n    print('Predicted: {}'.format(activity_map.get('c{}'.format(np.argmax(y_prediction)))))\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T14:17:43.971951Z","iopub.execute_input":"2022-04-22T14:17:43.972190Z","iopub.status.idle":"2022-04-22T14:17:43.980909Z","shell.execute_reply.started":"2022-04-22T14:17:43.972163Z","shell.execute_reply":"2022-04-22T14:17:43.979907Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"score1 = model.evaluate(x_test, y_test, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T14:17:43.982508Z","iopub.execute_input":"2022-04-22T14:17:43.982997Z","iopub.status.idle":"2022-04-22T14:18:00.763212Z","shell.execute_reply.started":"2022-04-22T14:17:43.982965Z","shell.execute_reply":"2022-04-22T14:18:00.762534Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"print('Loss: ', score1[0])\nprint('Accuracy: ', score1[1]*100, ' %')","metadata":{"execution":{"iopub.status.busy":"2022-04-22T14:18:00.765133Z","iopub.execute_input":"2022-04-22T14:18:00.765397Z","iopub.status.idle":"2022-04-22T14:18:00.771972Z","shell.execute_reply.started":"2022-04-22T14:18:00.765367Z","shell.execute_reply":"2022-04-22T14:18:00.770826Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"for i in range(10):\n    plot_test_class(model, test_files, i)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T14:18:00.773446Z","iopub.execute_input":"2022-04-22T14:18:00.773744Z","iopub.status.idle":"2022-04-22T14:18:04.142599Z","shell.execute_reply.started":"2022-04-22T14:18:00.773712Z","shell.execute_reply":"2022-04-22T14:18:04.141717Z"},"trusted":true},"execution_count":23,"outputs":[]}]}